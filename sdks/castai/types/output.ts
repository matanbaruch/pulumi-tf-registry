// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

export interface AksClusterTimeouts {
    create?: string;
    delete?: string;
    update?: string;
}

export interface AutoscalerAutoscalerSettings {
    /**
     * defines minimum and maximum amount of CPU the cluster can have.
     */
    clusterLimits?: outputs.AutoscalerAutoscalerSettingsClusterLimits;
    /**
     * enable/disable autoscaler policies
     */
    enabled?: boolean;
    /**
     * run autoscaler in scoped mode. Only marked pods and nodes will be considered.
     */
    isScopedMode?: boolean;
    /**
     * node downscaler defines policies for removing nodes based on the configured conditions.
     */
    nodeDownscaler?: outputs.AutoscalerAutoscalerSettingsNodeDownscaler;
    /**
     * marks whether partial matching should be used when deciding which custom node template to select.
     */
    nodeTemplatesPartialMatchingEnabled?: boolean;
    /**
     * policy defining whether autoscaler can use spot instances for provisioning additional workloads.
     */
    spotInstances?: outputs.AutoscalerAutoscalerSettingsSpotInstances;
    /**
     * policy defining autoscaler's behavior when unschedulable pods were detected.
     */
    unschedulablePods?: outputs.AutoscalerAutoscalerSettingsUnschedulablePods;
}

export interface AutoscalerAutoscalerSettingsClusterLimits {
    /**
     * defines the minimum and maximum amount of CPUs for cluster's worker nodes.
     */
    cpu?: outputs.AutoscalerAutoscalerSettingsClusterLimitsCpu;
    /**
     * enable/disable cluster size limits policy.
     */
    enabled?: boolean;
}

export interface AutoscalerAutoscalerSettingsClusterLimitsCpu {
    /**
     * defines the maximum allowed amount of vCPUs in the whole cluster.
     */
    maxCores?: number;
    /**
     * defines the minimum allowed amount of CPUs in the whole cluster.
     */
    minCores?: number;
}

export interface AutoscalerAutoscalerSettingsNodeDownscaler {
    /**
     * defines whether Node Downscaler should opt in for removing empty worker nodes when possible.
     */
    emptyNodes?: outputs.AutoscalerAutoscalerSettingsNodeDownscalerEmptyNodes;
    /**
     * enable/disable node downscaler policy.
     */
    enabled?: boolean;
    /**
     * defines the CAST AI Evictor component settings. Evictor watches the pods running in your cluster and looks for ways to compact them into fewer nodes, making nodes empty, which will be removed by the empty worker nodes policy.
     */
    evictor?: outputs.AutoscalerAutoscalerSettingsNodeDownscalerEvictor;
}

export interface AutoscalerAutoscalerSettingsNodeDownscalerEmptyNodes {
    /**
     * period (in seconds) to wait before removing the node. Might be useful to control the aggressiveness of the downscaler.
     */
    delaySeconds?: number;
    /**
     * enable/disable the empty worker nodes policy.
     */
    enabled?: boolean;
}

export interface AutoscalerAutoscalerSettingsNodeDownscalerEvictor {
    /**
     * enable/disable aggressive mode. By default, Evictor does not target nodes that are running unreplicated pods. This mode will make the Evictor start considering application with just a single replica.
     */
    aggressiveMode?: boolean;
    /**
     * configure the interval duration between Evictor operations. This property can be used to lower or raise the frequency of the Evictor's find-and-drain operations.
     */
    cycleInterval?: string;
    /**
     * enable/disable dry-run. This property allows you to prevent the Evictor from carrying any operations out and preview the actions it would take.
     */
    dryRun?: boolean;
    /**
     * enable/disable the Evictor policy. This will either install or uninstall the Evictor component in your cluster.
     */
    enabled?: boolean;
    /**
     * if enabled then Evictor will attempt to evict pods that have pod disruption budgets configured.
     */
    ignorePodDisruptionBudgets?: boolean;
    /**
     * configure the node grace period which controls the duration which must pass after a node has been created before Evictor starts considering that node.
     */
    nodeGracePeriodMinutes?: number;
    /**
     * configure the pod eviction failure back off interval. If pod eviction fails then Evictor will attempt to evict it again after the amount of time specified here.
     */
    podEvictionFailureBackOffInterval?: string;
    /**
     * enable/disable scoped mode. By default, Evictor targets all nodes in the cluster. This mode will constrain it to just the nodes which were created by CAST AI.
     */
    scopedMode?: boolean;
}

export interface AutoscalerAutoscalerSettingsSpotInstances {
    /**
     * enable/disable spot instances policy.
     */
    enabled?: boolean;
    /**
     * max allowed reclaim rate when choosing spot instance type. E.g. if the value is 10%, instance types having 10% or higher reclaim rate will not be considered. Set to zero to use all instance types regardless of reclaim rate.
     */
    maxReclaimRate?: number;
    /**
     * policy defining whether autoscaler can use spot backups instead of spot instances when spot instances are not available.
     */
    spotBackups?: outputs.AutoscalerAutoscalerSettingsSpotInstancesSpotBackups;
    /**
     * enable/disable spot diversity policy. When enabled, autoscaler will try to balance between diverse and cost optimal instance types.
     */
    spotDiversityEnabled?: boolean;
    /**
     * allowed node configuration price increase when diversifying instance types. E.g. if the value is 10%, then the overall price of diversified instance types can be 10% higher than the price of the optimal configuration.
     */
    spotDiversityPriceIncreaseLimit?: number;
    /**
     * configure the handling of SPOT interruption predictions.
     */
    spotInterruptionPredictions?: outputs.AutoscalerAutoscalerSettingsSpotInstancesSpotInterruptionPredictions;
}

export interface AutoscalerAutoscalerSettingsSpotInstancesSpotBackups {
    /**
     * enable/disable spot backups policy.
     */
    enabled?: boolean;
    /**
     * defines interval on how often spot backups restore to real spot should occur.
     */
    spotBackupRestoreRateSeconds?: number;
}

export interface AutoscalerAutoscalerSettingsSpotInstancesSpotInterruptionPredictions {
    /**
     * enable/disable spot interruption predictions.
     */
    enabled?: boolean;
    /**
     * define the type of the spot interruption prediction to handle. Allowed values are AWSRebalanceRecommendations, CASTAIInterruptionPredictions.
     */
    spotInterruptionPredictionsType?: string;
}

export interface AutoscalerAutoscalerSettingsUnschedulablePods {
    /**
     * enable/disable custom instances policy.
     */
    customInstancesEnabled?: boolean;
    /**
     * enable/disable unschedulable pods detection policy.
     */
    enabled?: boolean;
    /**
     * additional headroom based on cluster's total available capacity for on-demand nodes.
     */
    headroom?: outputs.AutoscalerAutoscalerSettingsUnschedulablePodsHeadroom;
    /**
     * additional headroom based on cluster's total available capacity for spot nodes.
     */
    headroomSpot?: outputs.AutoscalerAutoscalerSettingsUnschedulablePodsHeadroomSpot;
    /**
     * defines the node constraints that will be applied when autoscaling with Unschedulable Pods policy.
     */
    nodeConstraints?: outputs.AutoscalerAutoscalerSettingsUnschedulablePodsNodeConstraints;
}

export interface AutoscalerAutoscalerSettingsUnschedulablePodsHeadroom {
    /**
     * defines percentage of additional CPU capacity to be added.
     */
    cpuPercentage?: number;
    /**
     * enable/disable headroom policy.
     */
    enabled?: boolean;
    /**
     * defines percentage of additional memory capacity to be added.
     */
    memoryPercentage?: number;
}

export interface AutoscalerAutoscalerSettingsUnschedulablePodsHeadroomSpot {
    /**
     * defines percentage of additional CPU capacity to be added.
     */
    cpuPercentage?: number;
    /**
     * enable/disable headroom_spot policy.
     */
    enabled?: boolean;
    /**
     * defines percentage of additional memory capacity to be added.
     */
    memoryPercentage?: number;
}

export interface AutoscalerAutoscalerSettingsUnschedulablePodsNodeConstraints {
    /**
     * enable/disable node constraints policy.
     */
    enabled?: boolean;
    /**
     * defines max CPU cores for the node to pick.
     */
    maxCpuCores?: number;
    /**
     * defines max RAM in MiB for the node to pick.
     */
    maxRamMib?: number;
    /**
     * defines min CPU cores for the node to pick.
     */
    minCpuCores?: number;
    /**
     * defines min RAM in MiB for the node to pick.
     */
    minRamMib?: number;
}

export interface AutoscalerTimeouts {
    create?: string;
    update?: string;
}

export interface CommitmentsAzureReservation {
    allowedUsage: number;
    assignments: outputs.CommitmentsAzureReservationAssignment[];
    count: number;
    endTimestamp: string;
    id: string;
    instanceType: string;
    name: string;
    plan: string;
    prioritization: boolean;
    region: string;
    reservationId: string;
    reservationStatus: string;
    scalingStrategy: string;
    scope: string;
    scopeResourceGroup: string;
    scopeSubscription: string;
    startTimestamp: string;
    status: string;
}

export interface CommitmentsAzureReservationAssignment {
    clusterId: string;
    priority: number;
}

export interface CommitmentsCommitmentConfig {
    /**
     * Allowed usage of the commitment. The value is between 0 (0%) and 1 (100%).
     */
    allowedUsage?: number;
    /**
     * List of assigned clusters for the commitment. If prioritization is enabled, the order of the assignments indicates the priority. The first assignment has the highest priority.
     */
    assignments?: outputs.CommitmentsCommitmentConfigAssignment[];
    /**
     * Matcher used to map config to a commitment.
     */
    matcher: outputs.CommitmentsCommitmentConfigMatcher;
    /**
     * If enabled, it's possible to assign priorities to the assigned clusters.
     */
    prioritization?: boolean;
    /**
     * Scaling strategy of the commitment in CAST AI. One of: Default, CPUBased, RamBased
     */
    scalingStrategy?: string;
    /**
     * Status of the commitment in CAST AI.
     */
    status?: string;
}

export interface CommitmentsCommitmentConfigAssignment {
    /**
     * ID of the cluster to assign the commitment to.
     */
    clusterId: string;
    /**
     * Priority of the assignment. The lower the value, the higher the priority. 1 is the highest priority.
     */
    priority: number;
}

export interface CommitmentsCommitmentConfigMatcher {
    /**
     * Name of the commitment to match.
     */
    name: string;
    /**
     * Region of the commitment to match.
     */
    region: string;
    /**
     * Type of the commitment to match. For compute resources, it's the type of the machine.
     */
    type?: string;
}

export interface CommitmentsGcpCud {
    allowedUsage: number;
    assignments: outputs.CommitmentsGcpCudAssignment[];
    cpu: number;
    cudId: string;
    cudStatus: string;
    endTimestamp: string;
    id: string;
    memoryMb: number;
    name: string;
    plan: string;
    prioritization: boolean;
    region: string;
    scalingStrategy: string;
    startTimestamp: string;
    status: string;
    type: string;
}

export interface CommitmentsGcpCudAssignment {
    clusterId: string;
    priority: number;
}

export interface CommitmentsTimeouts {
    create?: string;
    update?: string;
}

export interface EksClusterTimeouts {
    create?: string;
    delete?: string;
    update?: string;
}

export interface EvictorAdvancedConfigEvictorAdvancedConfig {
    aggressive?: boolean;
    disposable?: boolean;
    /**
     * node selector
     */
    nodeSelectors?: outputs.EvictorAdvancedConfigEvictorAdvancedConfigNodeSelector[];
    /**
     * pod selector
     */
    podSelectors?: outputs.EvictorAdvancedConfigEvictorAdvancedConfigPodSelector[];
    removalDisabled?: boolean;
}

export interface EvictorAdvancedConfigEvictorAdvancedConfigNodeSelector {
    matchExpressions?: outputs.EvictorAdvancedConfigEvictorAdvancedConfigNodeSelectorMatchExpression[];
    matchLabels?: {[key: string]: string};
}

export interface EvictorAdvancedConfigEvictorAdvancedConfigNodeSelectorMatchExpression {
    key: string;
    operator: string;
    values?: string[];
}

export interface EvictorAdvancedConfigEvictorAdvancedConfigPodSelector {
    kind?: string;
    matchExpressions?: outputs.EvictorAdvancedConfigEvictorAdvancedConfigPodSelectorMatchExpression[];
    matchLabels?: {[key: string]: string};
    namespace?: string;
}

export interface EvictorAdvancedConfigEvictorAdvancedConfigPodSelectorMatchExpression {
    key: string;
    operator: string;
    values?: string[];
}

export interface EvictorAdvancedConfigTimeouts {
    create?: string;
    update?: string;
}

export interface GkeClusterTimeouts {
    create?: string;
    delete?: string;
    update?: string;
}

export interface NodeConfigurationAks {
    /**
     * Image OS Family to use when provisioning node in AKS. If both image and family are provided, the system will use provided image and provisioning logic for given family. If only image family is provided, the system will attempt to resolve the latest image from that family based on kubernetes version and node architecture. If image family is omitted, a default family (based on cloud provider) will be used. See Cast.ai documentation for details. Possible values: (ubuntu,azure-linux)
     */
    aksImageFamily?: string;
    /**
     * Maximum number of pods that can be run on a node, which affects how many IP addresses you will need for each node. Defaults to 30
     */
    maxPodsPerNode?: number;
    /**
     * Type of managed os disk attached to the node. (See [disk types](https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types)). One of: standard, standard-ssd, premium-ssd (ultra and premium-ssd-v2 are not supported for os disk)
     */
    osDiskType?: string;
}

export interface NodeConfigurationDefaultTimeouts {
    create?: string;
    delete?: string;
    read?: string;
}

export interface NodeConfigurationEks {
    /**
     * IP address to use for DNS queries within the cluster
     */
    dnsClusterIp?: string;
    /**
     * Image OS Family to use when provisioning node in EKS. If both image and family are provided, the system will use provided image and provisioning logic for given family. If only image family is provided, the system will attempt to resolve the latest image from that family based on kubernetes version and node architecture. If image family is omitted, a default family (based on cloud provider) will be used. See Cast.ai documentation for details. Possible values: (al2,al2023,bottlerocket)
     */
    eksImageFamily?: string;
    /**
     * Allow configure the IMDSv2 hop limit, the default is 2
     */
    imdsHopLimit?: number;
    /**
     * When the value is true both IMDSv1 and IMDSv2 are enabled. Setting the value to false disables permanently IMDSv1 and might affect legacy workloads running on the node created with this configuration. The default is true if the flag isn't provided
     */
    imdsV1?: boolean;
    /**
     * Cluster's instance profile ARN used for CAST provisioned nodes
     */
    instanceProfileArn: string;
    /**
     * Number of IPs per prefix to be used for calculating max pods.
     */
    ipsPerPrefix?: number;
    /**
     * AWS key pair ID to be used for CAST provisioned nodes. Has priority over ssh_public_key
     */
    keyPairId?: string;
    /**
     * Formula to calculate the maximum number of pods that can be run on a node. The following list of variables will be bound to a number before evaluating and can be used in the formula: NUM_MAX_NET_INTERFACES, NUM_IP_PER_INTERFACE, NUM_IP_PER_PREFIX, NUM_CPU, NUM_RAM_GB .
     */
    maxPodsPerNodeFormula?: string;
    /**
     * Cluster's security groups configuration for CAST provisioned nodes
     */
    securityGroups: string[];
    /**
     * AWS target groups configuration for CAST provisioned nodes
     */
    targetGroups?: outputs.NodeConfigurationEksTargetGroup[];
    /**
     * AWS EBS volume IOPS to be used for CAST provisioned nodes
     */
    volumeIops?: number;
    /**
     * AWS KMS key ARN for encrypting EBS volume attached to the node
     */
    volumeKmsKeyArn?: string;
    /**
     * AWS EBS volume throughput in MiB/s to be used for CAST provisioned nodes
     */
    volumeThroughput?: number;
    /**
     * AWS EBS volume type to be used for CAST provisioned nodes. One of: gp3, gp2, io1, io2
     */
    volumeType?: string;
}

export interface NodeConfigurationEksTargetGroup {
    /**
     * AWS target group ARN for CAST provisioned nodes
     */
    arn: string;
    /**
     * Port for AWS target group for CAST provisioned nodes
     */
    port?: number;
}

export interface NodeConfigurationGke {
    /**
     * Type of boot disk attached to the node. (See [disk types](https://cloud.google.com/compute/docs/disks#pdspecs)). One of: pd-standard, pd-balanced, pd-ssd, pd-extreme
     */
    diskType?: string;
    /**
     * Maximum number of pods that can be run on a node, which affects how many IP addresses you will need for each node. Defaults to 110
     */
    maxPodsPerNode?: number;
    /**
     * Network tags to be added on a VM. (See [network tags](https://cloud.google.com/vpc/docs/add-remove-network-tags))
     */
    networkTags?: string[];
    /**
     * Use ephemeral storage local SSD. Defaults to false
     */
    useEphemeralStorageLocalSsd?: boolean;
    /**
     * List of preferred availability zones to choose from when provisioning new nodes.
     *
     * @deprecated Deprecated
     */
    zones?: string[];
}

export interface NodeConfigurationKops {
    /**
     * AWS key pair ID to be used for provisioned nodes. Has priority over sshPublicKey
     */
    keyPairId?: string;
}

export interface NodeConfigurationTimeouts {
    create?: string;
    delete?: string;
    read?: string;
    update?: string;
}

export interface NodeTemplateConstraints {
    /**
     * List of acceptable instance CPU architectures, the default is amd64. Allowed values: amd64, arm64.
     */
    architectures: string[];
    /**
     * The list of AZ names to consider for the node template, if empty or not set all AZs are considered.
     */
    azs?: string[];
    /**
     * Will include burstable instances when enabled otherwise they will be excluded. Supported values: `enabled`, `disabled` or ``.
     */
    burstableInstances?: string;
    /**
     * Compute optimized instance constraint (deprecated).
     */
    computeOptimized?: boolean;
    /**
     * Will only include compute optimized nodes when enabled and exclude compute optimized nodes when disabled. Empty value won't have effect on instances filter. Supported values: `enabled`, `disabled` or empty string.
     */
    computeOptimizedState?: string;
    /**
     * List of acceptable CPU manufacturers. Allowed values: AMD, AMPERE, APPLE, AWS, INTEL.
     */
    cpuManufacturers?: string[];
    customPriorities?: outputs.NodeTemplateConstraintsCustomPriority[];
    /**
     * Will include customer specific (preview) instances when enabled otherwise they will be excluded. Supported values: `enabled`, `disabled` or ``.
     */
    customerSpecific?: string;
    /**
     * Dedicated node affinity - creates preference for instances to be created on sole tenancy or dedicated nodes. This
     *  feature is only available for GCP clusters and sole tenancy nodes with local
     *  SSDs or GPUs are not supported. If the sole tenancy or dedicated nodes don't have capacity for selected instance
     *  type, the Autoscaler will fall back to multi-tenant instance types available for this Node Template.
     *  Other instance constraints are applied when the Autoscaler picks available instance types that can be created on
     *  the sole tenancy or dedicated node (example: setting min CPU to 16).
     */
    dedicatedNodeAffinities?: outputs.NodeTemplateConstraintsDedicatedNodeAffinity[];
    /**
     * Enable/disable spot diversity policy. When enabled, autoscaler will try to balance between diverse and cost optimal instance types.
     */
    enableSpotDiversity?: boolean;
    /**
     * Fallback restore rate in seconds: defines how much time should pass before spot fallback should be attempted to be restored to real spot.
     */
    fallbackRestoreRateSeconds?: number;
    gpu?: outputs.NodeTemplateConstraintsGpu;
    instanceFamilies?: outputs.NodeTemplateConstraintsInstanceFamilies;
    /**
     * GPU instance constraint - will only pick nodes with GPU if true
     */
    isGpuOnly?: boolean;
    /**
     * Max CPU cores per node.
     */
    maxCpu?: number;
    /**
     * Max Memory (Mib) per node.
     */
    maxMemory?: number;
    /**
     * Min CPU cores per node.
     */
    minCpu?: number;
    /**
     * Min Memory (Mib) per node.
     */
    minMemory?: number;
    /**
     * Should include on-demand instances in the considered pool.
     */
    onDemand: boolean;
    /**
     * List of acceptable instance Operating Systems, the default is linux. Allowed values: linux, windows.
     */
    os: string[];
    /**
     * Should include spot instances in the considered pool.
     */
    spot?: boolean;
    /**
     * Allowed node configuration price increase when diversifying instance types. E.g. if the value is 10%, then the overall price of diversified instance types can be 10% higher than the price of the optimal configuration.
     */
    spotDiversityPriceIncreaseLimitPercent?: number;
    /**
     * Enable/disable spot interruption predictions.
     */
    spotInterruptionPredictionsEnabled?: boolean;
    /**
     * Spot interruption predictions type. Can be either "aws-rebalance-recommendations" or "interruption-predictions".
     */
    spotInterruptionPredictionsType?: string;
    /**
     * Storage optimized instance constraint (deprecated).
     */
    storageOptimized?: boolean;
    /**
     * Storage optimized instance constraint - will only pick storage optimized nodes if enabled and won't pick if disabled. Empty value will have no effect. Supported values: `enabled`, `disabled` or empty string.
     */
    storageOptimizedState?: string;
    /**
     * Spot instance fallback constraint - when true, on-demand instances will be created, when spots are unavailable.
     */
    useSpotFallbacks?: boolean;
}

export interface NodeTemplateConstraintsCustomPriority {
    /**
     * Instance families to prioritize in this tier.
     */
    instanceFamilies?: string[];
    /**
     * If true, this tier will apply to on-demand instances.
     */
    onDemand?: boolean;
    /**
     * If true, this tier will apply to spot instances.
     */
    spot?: boolean;
}

export interface NodeTemplateConstraintsDedicatedNodeAffinity {
    affinities?: outputs.NodeTemplateConstraintsDedicatedNodeAffinityAffinity[];
    /**
     * Availability zone name.
     */
    azName: string;
    /**
     * Instance/node types in this node group.
     */
    instanceTypes: string[];
    /**
     * Name of node group.
     */
    name: string;
}

export interface NodeTemplateConstraintsDedicatedNodeAffinityAffinity {
    /**
     * Key of the node affinity selector.
     */
    key: string;
    /**
     * Operator of the node affinity selector. Allowed values: In, NotIn, Exists, DoesNotExist, Gt, Lt.
     */
    operator: string;
    /**
     * Values of the node affinity selector.
     */
    values: string[];
}

export interface NodeTemplateConstraintsGpu {
    /**
     * Names of the GPUs to exclude.
     */
    excludeNames?: string[];
    /**
     * Instance families to include when filtering (excludes all other families).
     */
    includeNames?: string[];
    /**
     * Manufacturers of the gpus to select - NVIDIA, AMD.
     */
    manufacturers?: string[];
    /**
     * Max GPU count for the instance type to have.
     */
    maxCount?: number;
    /**
     * Min GPU count for the instance type to have.
     */
    minCount?: number;
}

export interface NodeTemplateConstraintsInstanceFamilies {
    /**
     * Instance families to include when filtering (excludes all other families).
     */
    excludes?: string[];
    /**
     * Instance families to exclude when filtering (includes all other families).
     */
    includes?: string[];
}

export interface NodeTemplateCustomTaint {
    /**
     * Effect of a taint to be added to nodes created from this template, the default is NoSchedule. Allowed values: NoSchedule, NoExecute.
     */
    effect?: string;
    /**
     * Key of a taint to be added to nodes created from this template.
     */
    key: string;
    /**
     * Value of a taint to be added to nodes created from this template.
     */
    value?: string;
}

export interface NodeTemplateTimeouts {
    create?: string;
    delete?: string;
    read?: string;
    update?: string;
}

export interface OrganizationMembersTimeouts {
    create?: string;
    delete?: string;
    update?: string;
}

export interface RebalancingJobTimeouts {
    create?: string;
    delete?: string;
    read?: string;
    update?: string;
}

export interface RebalancingScheduleLaunchConfiguration {
    /**
     * When enabled rebalancing will also consider problematic pods (pods without controller, job pods, pods with removal-disabled annotation) as not-problematic.
     */
    aggressiveMode?: boolean;
    executionConditions?: outputs.RebalancingScheduleLaunchConfigurationExecutionConditions;
    /**
     * Defines whether the nodes that failed to get drained until a predefined timeout, will be kept with a rebalancing.cast.ai/status=drain-failed annotation instead of forcefully drained.
     */
    keepDrainTimeoutNodes?: boolean;
    /**
     * Specifies amount of time since node creation before the node is allowed to be considered for automated rebalancing.
     */
    nodeTtlSeconds?: number;
    /**
     * Maximum number of nodes that will be selected for rebalancing.
     */
    numTargetedNodes?: number;
    /**
     * Minimum number of nodes that should be kept in the cluster after rebalancing.
     */
    rebalancingMinNodes?: number;
    /**
     * Node selector in JSON format.
     */
    selector?: string;
    /**
     * Defines the algorithm used to select the target nodes for rebalancing.
     */
    targetNodeSelectionAlgorithm?: string;
}

export interface RebalancingScheduleLaunchConfigurationExecutionConditions {
    /**
     * The percentage of the predicted savings that must be achieved in order to fully execute the plan.If the savings are not achieved after creating the new nodes, the plan will fail and delete the created nodes.
     */
    achievedSavingsPercentage?: number;
    /**
     * Enables or disables the execution conditions.
     */
    enabled: boolean;
}

export interface RebalancingScheduleSchedule {
    /**
     * Cron expression defining when the schedule should trigger.
     *
     *   The `cron` expression can optionally include the `CRON_TZ` variable at the beginning to specify the timezone in which the schedule should be interpreted.
     *
     *   Example:
     *   ```plaintext
     *   CRON_TZ=America/New_York 0 12 * * ?
     *   ```
     *   In the example above, the `CRON_TZ` variable is set to "America/New_York" indicating that the cron expression should be interpreted in the Eastern Time (ET) timezone.
     *
     *   To retrieve a list of available timezone values, you can use the following API endpoint:
     *
     *   GET https://api.cast.ai/v1/time-zones
     *
     *   When using the `CRON_TZ` variable, ensure that the specified timezone is valid and supported by checking the list of available timezones from the API endpoint.  If the `CRON_TZ` variable is not specified, the cron expression will be interpreted in the UTC timezone.
     */
    cron: string;
}

export interface RebalancingScheduleTimeouts {
    create?: string;
    delete?: string;
    read?: string;
    update?: string;
}

export interface RebalancingScheduleTriggerConditions {
    /**
     * If true, the savings percentage will be ignored and the rebalancing will be triggered regardless of the savings percentage.
     */
    ignoreSavings?: boolean;
    /**
     * Defines the minimum percentage of savings expected.
     */
    savingsPercentage: number;
}

export interface ReservationsReservation {
    count: string;
    endDate: string;
    instanceType: string;
    name: string;
    price: string;
    provider: string;
    region: string;
    startDate: string;
    zoneId: string;
    zoneName: string;
}

export interface ReservationsTimeouts {
    create?: string;
    update?: string;
}

export interface SsoConnectionAad {
    /**
     * Azure AD domain
     */
    adDomain: string;
    /**
     * Azure AD client ID
     */
    clientId: string;
    /**
     * Azure AD client secret
     */
    clientSecret: string;
}

export interface SsoConnectionOkta {
    /**
     * Okta client ID
     */
    clientId: string;
    /**
     * Okta client secret
     */
    clientSecret: string;
    /**
     * Okta domain
     */
    oktaDomain: string;
}

export interface SsoConnectionTimeouts {
    create?: string;
    delete?: string;
    update?: string;
}

export interface WorkloadScalingPolicyCpu {
    /**
     * The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
     */
    applyThreshold?: number;
    /**
     * The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
     */
    args?: string[];
    /**
     * The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
     */
    function?: string;
    /**
     * Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
     */
    overhead?: number;
}

export interface WorkloadScalingPolicyMemory {
    /**
     * The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
     */
    applyThreshold?: number;
    /**
     * The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
     */
    args?: string[];
    /**
     * The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
     */
    function?: string;
    /**
     * Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
     */
    overhead?: number;
}

export interface WorkloadScalingPolicyTimeouts {
    create?: string;
    delete?: string;
    read?: string;
    update?: string;
}

