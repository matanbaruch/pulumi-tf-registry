// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

export class KafkaClusterTopic extends pulumi.CustomResource {
    /**
     * Get an existing KafkaClusterTopic resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: KafkaClusterTopicState, opts?: pulumi.CustomResourceOptions): KafkaClusterTopic {
        return new KafkaClusterTopic(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'ionoscloud:index/kafkaClusterTopic:KafkaClusterTopic';

    /**
     * Returns true if the given object is an instance of KafkaClusterTopic.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is KafkaClusterTopic {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === KafkaClusterTopic.__pulumiType;
    }

    /**
     * The ID of the Kafka Cluster to which the topic belongs.
     */
    public readonly clusterId!: pulumi.Output<string>;
    /**
     * The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl, es/vit, gb/lhr, us/ewr, us/las, us/mci,
     * fr/par
     */
    public readonly location!: pulumi.Output<string>;
    /**
     * The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
     * character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
     */
    public readonly name!: pulumi.Output<string>;
    /**
     * The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
     * greater than or equal to the replication factor.
     */
    public readonly numberOfPartitions!: pulumi.Output<number | undefined>;
    /**
     * The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
     * different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
     */
    public readonly replicationFactor!: pulumi.Output<number | undefined>;
    /**
     * This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
     * space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
     */
    public readonly retentionTime!: pulumi.Output<number | undefined>;
    /**
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
     * a larger segment size means fewer files but less granular control over retention.
     */
    public readonly segmentBytes!: pulumi.Output<number | undefined>;
    public readonly timeouts!: pulumi.Output<outputs.KafkaClusterTopicTimeouts | undefined>;

    /**
     * Create a KafkaClusterTopic resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: KafkaClusterTopicArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: KafkaClusterTopicArgs | KafkaClusterTopicState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as KafkaClusterTopicState | undefined;
            resourceInputs["clusterId"] = state ? state.clusterId : undefined;
            resourceInputs["location"] = state ? state.location : undefined;
            resourceInputs["name"] = state ? state.name : undefined;
            resourceInputs["numberOfPartitions"] = state ? state.numberOfPartitions : undefined;
            resourceInputs["replicationFactor"] = state ? state.replicationFactor : undefined;
            resourceInputs["retentionTime"] = state ? state.retentionTime : undefined;
            resourceInputs["segmentBytes"] = state ? state.segmentBytes : undefined;
            resourceInputs["timeouts"] = state ? state.timeouts : undefined;
        } else {
            const args = argsOrState as KafkaClusterTopicArgs | undefined;
            if ((!args || args.clusterId === undefined) && !opts.urn) {
                throw new Error("Missing required property 'clusterId'");
            }
            if ((!args || args.location === undefined) && !opts.urn) {
                throw new Error("Missing required property 'location'");
            }
            resourceInputs["clusterId"] = args ? args.clusterId : undefined;
            resourceInputs["location"] = args ? args.location : undefined;
            resourceInputs["name"] = args ? args.name : undefined;
            resourceInputs["numberOfPartitions"] = args ? args.numberOfPartitions : undefined;
            resourceInputs["replicationFactor"] = args ? args.replicationFactor : undefined;
            resourceInputs["retentionTime"] = args ? args.retentionTime : undefined;
            resourceInputs["segmentBytes"] = args ? args.segmentBytes : undefined;
            resourceInputs["timeouts"] = args ? args.timeouts : undefined;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        super(KafkaClusterTopic.__pulumiType, name, resourceInputs, opts, false /*dependency*/, utilities.getPackage());
    }
}

/**
 * Input properties used for looking up and filtering KafkaClusterTopic resources.
 */
export interface KafkaClusterTopicState {
    /**
     * The ID of the Kafka Cluster to which the topic belongs.
     */
    clusterId?: pulumi.Input<string>;
    /**
     * The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl, es/vit, gb/lhr, us/ewr, us/las, us/mci,
     * fr/par
     */
    location?: pulumi.Input<string>;
    /**
     * The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
     * character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
     */
    name?: pulumi.Input<string>;
    /**
     * The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
     * greater than or equal to the replication factor.
     */
    numberOfPartitions?: pulumi.Input<number>;
    /**
     * The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
     * different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
     */
    replicationFactor?: pulumi.Input<number>;
    /**
     * This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
     * space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
     */
    retentionTime?: pulumi.Input<number>;
    /**
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
     * a larger segment size means fewer files but less granular control over retention.
     */
    segmentBytes?: pulumi.Input<number>;
    timeouts?: pulumi.Input<inputs.KafkaClusterTopicTimeouts>;
}

/**
 * The set of arguments for constructing a KafkaClusterTopic resource.
 */
export interface KafkaClusterTopicArgs {
    /**
     * The ID of the Kafka Cluster to which the topic belongs.
     */
    clusterId: pulumi.Input<string>;
    /**
     * The location of your Kafka Cluster Topic. Supported locations: de/fra, de/txl, es/vit, gb/lhr, us/ewr, us/las, us/mci,
     * fr/par
     */
    location: pulumi.Input<string>;
    /**
     * The name of your Kafka Cluster Topic. Must be 63 characters or less and must begin and end with an alphanumeric
     * character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
     */
    name?: pulumi.Input<string>;
    /**
     * The number of partitions of the topic. Partitions allow for parallel processing of messages. The partition count must be
     * greater than or equal to the replication factor.
     */
    numberOfPartitions?: pulumi.Input<number>;
    /**
     * The number of replicas of the topic. The replication factor determines how many copies of the topic are stored on
     * different brokers. The replication factor must be less than or equal to the number of brokers in the Kafka Cluster.
     */
    replicationFactor?: pulumi.Input<number>;
    /**
     * This configuration controls the maximum time we will retain a log before we will discard old log segments to free up
     * space. This represents an SLA on how soon consumers must read their data. If set to -1, no time limit is applied.
     */
    retentionTime?: pulumi.Input<number>;
    /**
     * This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so
     * a larger segment size means fewer files but less granular control over retention.
     */
    segmentBytes?: pulumi.Input<number>;
    timeouts?: pulumi.Input<inputs.KafkaClusterTopicTimeouts>;
}
