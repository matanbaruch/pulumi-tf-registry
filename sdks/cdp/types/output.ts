// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

export interface DatahubAwsClusterClusterExtension {
    customProperties?: string;
}

export interface DatahubAwsClusterDestroyOptions {
    /**
     * An indicator that will take place once the cluster termination will be performed. If it is true, that means if something would go sideways during termination, the operation will proceed, however in such a case no notification would come thus it is advisable to check the cloud provider if there are no leftover resources once the destroy is finished.
     */
    forceDeleteCluster: boolean;
}

export interface DatahubAwsClusterImage {
    catalog?: string;
    id: string;
    os?: string;
}

export interface DatahubAwsClusterInstanceGroup {
    /**
     * Configuration regarding the attached volume to the specific instance group.
     */
    attachedVolumeConfigurations: outputs.DatahubAwsClusterInstanceGroupAttachedVolumeConfiguration[];
    /**
     * The set of availability zones that are going to be used for cluster creation on the given instance group.
     */
    availabilityZones?: string[];
    /**
     * The name of the instance group.
     */
    instanceGroupName: string;
    /**
     * The type of the instance group.
     */
    instanceGroupType: string;
    /**
     * The cloud provider-side instance type.
     */
    instanceType: string;
    /**
     * The cluster node count. Has to be greater or equal than 0 and less than 100,000.
     */
    nodeCount: number;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    recipes?: string[];
    /**
     * The type of the recovery mode.
     */
    recoveryMode: string;
    /**
     * The size of the root volume in GB
     */
    rootVolumeSize: number;
    /**
     * The volume encryption related configuration.
     */
    volumeEncryption: outputs.DatahubAwsClusterInstanceGroupVolumeEncryption;
}

export interface DatahubAwsClusterInstanceGroupAttachedVolumeConfiguration {
    /**
     * The number of volumes to be attached.
     */
    volumeCount: number;
    /**
     * The size of the volume in GB.
     */
    volumeSize: number;
    /**
     * The - cloud provider - type of the volume.
     */
    volumeType: string;
}

export interface DatahubAwsClusterInstanceGroupVolumeEncryption {
    encryption: boolean;
}

export interface DatahubAwsClusterPollingOptions {
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface DatahubAzureClusterClusterExtension {
    customProperties?: string;
}

export interface DatahubAzureClusterDestroyOptions {
    /**
     * An indicator that will take place once the cluster termination will be performed. If it is true, that means if something would go sideways during termination, the operation will proceed, however in such a case no notification would come thus it is advisable to check the cloud provider if there are no leftover resources once the destroy is finished.
     */
    forceDeleteCluster: boolean;
}

export interface DatahubAzureClusterImage {
    catalog?: string;
    id: string;
    os?: string;
}

export interface DatahubAzureClusterInstanceGroup {
    /**
     * Configuration regarding the attached volume to the specific instance group.
     */
    attachedVolumeConfigurations: outputs.DatahubAzureClusterInstanceGroupAttachedVolumeConfiguration[];
    /**
     * List of availability zones that this instance group is associated with.
     */
    availabilityZones?: string[];
    /**
     * The name of the instance group.
     */
    instanceGroupName: string;
    /**
     * The type of the instance group.
     */
    instanceGroupType: string;
    /**
     * The cloud provider-side instance type.
     */
    instanceType: string;
    /**
     * The cluster node count. Has to be greater or equal than 0 and less than 100,000.
     */
    nodeCount: number;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    recipes?: string[];
    /**
     * The type of the recovery mode.
     */
    recoveryMode: string;
    /**
     * The size of the root volume in GB
     */
    rootVolumeSize: number;
    /**
     * The volume encryption related configuration.
     */
    volumeEncryption: outputs.DatahubAzureClusterInstanceGroupVolumeEncryption;
}

export interface DatahubAzureClusterInstanceGroupAttachedVolumeConfiguration {
    /**
     * The number of volumes to be attached.
     */
    volumeCount: number;
    /**
     * The size of the volume in GB.
     */
    volumeSize: number;
    /**
     * The - cloud provider - type of the volume.
     */
    volumeType: string;
}

export interface DatahubAzureClusterInstanceGroupVolumeEncryption {
    encryption: boolean;
}

export interface DatahubAzureClusterPollingOptions {
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface DatahubGcpClusterClusterExtension {
    customProperties?: string;
}

export interface DatahubGcpClusterDestroyOptions {
    /**
     * An indicator that will take place once the cluster termination will be performed. If it is true, that means if something would go sideways during termination, the operation will proceed, however in such a case no notification would come thus it is advisable to check the cloud provider if there are no leftover resources once the destroy is finished.
     */
    forceDeleteCluster: boolean;
}

export interface DatahubGcpClusterImage {
    catalog?: string;
    id: string;
    os?: string;
}

export interface DatahubGcpClusterInstanceGroup {
    /**
     * Configuration regarding the attached volume to the specific instance group.
     */
    attachedVolumeConfigurations: outputs.DatahubGcpClusterInstanceGroupAttachedVolumeConfiguration[];
    /**
     * The name of the instance group.
     */
    instanceGroupName: string;
    /**
     * The type of the instance group.
     */
    instanceGroupType: string;
    /**
     * The cloud provider-side instance type.
     */
    instanceType: string;
    /**
     * The cluster node count. Has to be greater or equal than 0 and less than 100,000.
     */
    nodeCount: number;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    recipes?: string[];
    /**
     * The type of the recovery mode.
     */
    recoveryMode: string;
    /**
     * The size of the root volume in GB
     */
    rootVolumeSize: number;
}

export interface DatahubGcpClusterInstanceGroupAttachedVolumeConfiguration {
    /**
     * The number of volumes to be attached.
     */
    volumeCount: number;
    /**
     * The size of the volume in GB.
     */
    volumeSize: number;
    /**
     * The - cloud provider - type of the volume.
     */
    volumeType: string;
}

export interface DatahubGcpClusterPollingOptions {
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface DatalakeAwsDatalakeImage {
    catalog?: string;
    id: string;
    os?: string;
}

export interface DatalakeAwsDatalakePollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface DatalakeAwsDatalakeRecipe {
    /**
     * The name of the designated instance group.
     */
    instanceGroupName: string;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    recipeNames: string[];
}

export interface DatalakeAzureDatalakeImage {
    catalog?: string;
    id: string;
    os?: string;
}

export interface DatalakeAzureDatalakePollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface DatalakeAzureDatalakeRecipe {
    /**
     * The name of the designated instance group.
     */
    instanceGroupName: string;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    recipeNames: string[];
}

export interface DatalakeGcpDatalakeCloudProviderConfiguration {
    serviceAccountEmail: string;
    storageLocation: string;
}

export interface DatalakeGcpDatalakeImage {
    catalogName?: string;
    id: string;
    os?: string;
}

export interface DatalakeGcpDatalakePollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface DatalakeGcpDatalakeRecipe {
    /**
     * The name of the designated instance group.
     */
    instanceGroupName: string;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    recipeNames: string[];
}

export interface DeServiceChartValueOverride {
    /**
     * Name of the chart that has to be overridden, for eg- "dex-app", "dex-base".
     */
    chartName: string;
    /**
     * Space separated key-value pairs for overriding chart values. The key and the value must be separated using a colon(:) For eg- "airflow.enabled:true safari.enabled:true".
     */
    overrides: string;
}

export interface DeServiceCustomAzureFilesConfigs {
    /**
     * Azure File Share's server address. Defaults to '<storageaccount>.file.core.windows.net'.
     */
    azureFilesFqdn?: string;
    /**
     * Resource Group of the Storage Account.
     */
    resourceGroup: string;
    /**
     * Azure Storage Account of the File Share.
     */
    storageAccountName: string;
}

export interface DwAwsClusterCustomRegistryOptions {
    /**
     * Registry type, supported values are ECR or ACR.
     */
    registryType: string;
    /**
     * The URL of the registry.
     */
    repositoryUrl: string;
}

export interface DwAwsClusterInstanceSettings {
    /**
     * The additional instance types that the environment is allowed to use, listed in their priority order. They will be used instead of the primary compute instance type in case it is unavailable. You cannot include any instance type that was already indicated in computeInstanceTypes.
     */
    additionalInstanceTypes?: string[];
    /**
     * The compute instance types that the environment is restricted to use. This affects the creation of virtual warehouses where this restriction will apply. Select an instance type that meets your computing, memory, networking, or storage needs. As of now, only a single instance type can be listed.
     */
    computeInstanceTypes?: string[];
    /**
     * The custom AMI ID to use for worker nodes.
     */
    customAmiId?: string;
    /**
     * Whether to use spot instances for worker nodes.
     */
    enableSpotInstances: boolean;
}

export interface DwAwsClusterNetworkSettings {
    /**
     * The list of subnet IDs for the load balancer.
     */
    loadBalancerSubnetIds: string[];
    /**
     * Whether to use overlay network.
     */
    useOverlayNetwork: boolean;
    /**
     * Whether to use private IP addresses for the load balancer. Determines workload endpoint access.
     */
    usePrivateLoadBalancer: boolean;
    /**
     * Whether to use public IP addresses for worker nodes.
     */
    usePublicWorkerNode: boolean;
    /**
     * The list of IP CIDRs to allow access for kubernetes cluster API endpoint.
     */
    whitelistK8sClusterAccessIpCidrs?: string[];
    /**
     * The list of IP CIDRs to allow access for workload endpoints.
     */
    whitelistWorkloadAccessIpCidrs?: string[];
    /**
     * The list of subnet IDs for worker nodes.
     */
    workerSubnetIds: string[];
}

export interface EnvironmentsAwsEnvironmentAuthentication {
    publicKey?: string;
    publicKeyId?: string;
}

export interface EnvironmentsAwsEnvironmentFreeipa {
    catalog?: string;
    imageId?: string;
    instanceCountByGroup?: number;
    instanceType?: string;
    instances: outputs.EnvironmentsAwsEnvironmentFreeipaInstance[];
    multiAz?: boolean;
    os?: string;
    recipes: string[];
}

export interface EnvironmentsAwsEnvironmentFreeipaInstance {
    availabilityZone: string;
    discoveryFqdn: string;
    instanceGroup: string;
    instanceId: string;
    instanceStatus: string;
    instanceStatusReason: string;
    instanceType: string;
    instanceVmType: string;
    lifeCycle: string;
    privateIp: string;
    publicIp: string;
    sshPort: number;
    subnetId: string;
}

export interface EnvironmentsAwsEnvironmentLogStorage {
    backupStorageLocationBase: string;
    instanceProfile: string;
    storageLocationBase: string;
}

export interface EnvironmentsAwsEnvironmentPollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface EnvironmentsAwsEnvironmentSecurityAccess {
    cidr: string;
    defaultSecurityGroupId: string;
    defaultSecurityGroupIds?: string[];
    securityGroupIdForKnox: string;
    securityGroupIdsForKnoxes?: string[];
}

export interface EnvironmentsAzureCredentialAppBased {
    /**
     * The ID of the application registered in Azure.
     */
    applicationId: string;
    /**
     * The client secret key (also referred to as application password) for the registered application.
     */
    secretKey: string;
}

export interface EnvironmentsAzureEnvironmentExistingNetworkParams {
    aksPrivateDnsZoneId: string;
    databasePrivateDnsZoneId: string;
    flexibleServerSubnetIds: string[];
    networkId: string;
    resourceGroupName: string;
    subnetIds: string[];
}

export interface EnvironmentsAzureEnvironmentFreeipa {
    catalog?: string;
    imageId?: string;
    instanceCountByGroup?: number;
    instanceType?: string;
    instances: outputs.EnvironmentsAzureEnvironmentFreeipaInstance[];
    multiAz?: boolean;
    os?: string;
    recipes: string[];
}

export interface EnvironmentsAzureEnvironmentFreeipaInstance {
    availabilityZone: string;
    discoveryFqdn: string;
    instanceGroup: string;
    instanceId: string;
    instanceStatus: string;
    instanceStatusReason: string;
    instanceType: string;
    instanceVmType: string;
    lifeCycle: string;
    privateIp: string;
    publicIp: string;
    sshPort: number;
    subnetId: string;
}

export interface EnvironmentsAzureEnvironmentLogStorage {
    backupStorageLocationBase: string;
    managedIdentity: string;
    storageLocationBase: string;
}

export interface EnvironmentsAzureEnvironmentNewNetworkParams {
    networkCidr: string;
}

export interface EnvironmentsAzureEnvironmentPollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface EnvironmentsAzureEnvironmentSecurityAccess {
    cidr: string;
    defaultSecurityGroupId: string;
    defaultSecurityGroupIds?: string[];
    securityGroupIdForKnox: string;
    securityGroupIdsForKnoxes?: string[];
}

export interface EnvironmentsGcpEnvironmentExistingNetworkParams {
    /**
     * The name of the GCP VPC.
     */
    networkName: string;
    /**
     * The ID of the Google project associated with the VPC.
     */
    sharedProjectId: string;
    /**
     * One or more subnet names within the VPC. Google VPCs are global, please give subnets from single geographic region only to reduce latency.
     */
    subnetNames: string[];
}

export interface EnvironmentsGcpEnvironmentFreeipa {
    catalog?: string;
    imageId?: string;
    instanceCountByGroup?: number;
    instanceType?: string;
    instances: outputs.EnvironmentsGcpEnvironmentFreeipaInstance[];
    multiAz?: boolean;
    os?: string;
    recipes: string[];
}

export interface EnvironmentsGcpEnvironmentFreeipaInstance {
    availabilityZone: string;
    discoveryFqdn: string;
    instanceGroup: string;
    instanceId: string;
    instanceStatus: string;
    instanceStatusReason: string;
    instanceType: string;
    instanceVmType: string;
    lifeCycle: string;
    privateIp: string;
    publicIp: string;
    sshPort: number;
    subnetId: string;
}

export interface EnvironmentsGcpEnvironmentLogStorage {
    /**
     * The Google storage bucket to use. This should be a gs:// url.
     */
    backupStorageLocationBase: string;
    /**
     * Email id of the service account to be associated with the instances. This service account should have "storage.ObjectCreator" role on the given storage bucket.
     */
    serviceAccountEmail: string;
    /**
     * The Google storage bucket to use. This should be a gs:// url.
     */
    storageLocationBase: string;
}

export interface EnvironmentsGcpEnvironmentPollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface EnvironmentsGcpEnvironmentSecurityAccess {
    /**
     * Firewall rule for other hosts.
     */
    defaultSecurityGroupId: string;
    /**
     * Firewall rule for Knox hosts.
     */
    securityGroupIdForKnox: string;
}

export interface EnvironmentsIdBrokerMappingsMapping {
    accessorCrn: string;
    role: string;
}

export interface IamMachineUserAzureCloudIdentity {
    environmentCrn: string;
    objectId: string;
}

export interface IamMachineUserWorkloadPasswordDetails {
    expirationDate: string;
    isPasswordSet: boolean;
    minLifetimeDate: string;
}

export interface MlWorkspaceExistingDatabaseConfig {
    /**
     * Optionally provide a Postgresql database host to export model metrics to.
     */
    existingDatabaseHost?: string;
    /**
     * Optionally provide a Postgresql database name to export model metrics to.
     */
    existingDatabaseName?: string;
    /**
     * Optionally provide a Postgresql database password to use when exporting model metrics.
     */
    existingDatabasePassword?: string;
    /**
     * Optionally provide a Postgresql database port to export model metrics to.
     */
    existingDatabasePort?: string;
    /**
     * Optionally provide a Postgresql database user to use when exporting model metrics.
     */
    existingDatabaseUser?: string;
}

export interface MlWorkspaceProvisionK8sRequest {
    /**
     * The name of the environment for the workspace to create.
     */
    environmentName: string;
    /**
     * The instance groups.
     */
    instanceGroups: outputs.MlWorkspaceProvisionK8sRequestInstanceGroup[];
    /**
     * The overlay network for an AWS Kubernetes cluster's CNI.
     */
    network?: outputs.MlWorkspaceProvisionK8sRequestNetwork;
    /**
     * Tags to add to the cloud provider resources created. This is in addition to any tags added by Cloudera.
     */
    tags?: outputs.MlWorkspaceProvisionK8sRequestTag[];
}

export interface MlWorkspaceProvisionK8sRequestInstanceGroup {
    /**
     * The auto scaling configuration.
     */
    autoscaling?: outputs.MlWorkspaceProvisionK8sRequestInstanceGroupAutoscaling;
    /**
     * The networking rules for the ingress.
     */
    ingressRules?: string[];
    /**
     * The initial number of instance node.
     */
    instanceCount?: number;
    /**
     * The tier of the instance i.e. on-demand/spot.
     */
    instanceTier?: string;
    /**
     * The cloud provider instance type for the node instance.
     */
    instanceType: string;
    /**
     * The unique name of the instance group.
     */
    name?: string;
    /**
     * The root volume of the instance.
     */
    rootVolume?: outputs.MlWorkspaceProvisionK8sRequestInstanceGroupRootVolume;
}

export interface MlWorkspaceProvisionK8sRequestInstanceGroupAutoscaling {
    /**
     * The boolean flag to enable the auto scaling.
     */
    enabled?: boolean;
    /**
     * The maximum number of instance for auto scaling.
     */
    maxInstances: number;
    /**
     * The minimum number of instance for auto scaling.
     */
    minInstances: number;
}

export interface MlWorkspaceProvisionK8sRequestInstanceGroupRootVolume {
    /**
     * The volume size in GB.
     */
    size: number;
}

export interface MlWorkspaceProvisionK8sRequestNetwork {
    /**
     * The plugin specifies specific cni vendor, ex: calico, weave etc.
     */
    plugin?: string;
    /**
     * The options for overlay topology.
     */
    topology?: outputs.MlWorkspaceProvisionK8sRequestNetworkTopology;
}

export interface MlWorkspaceProvisionK8sRequestNetworkTopology {
    /**
     * The options for subnets.
     */
    subnets: string[];
}

export interface MlWorkspaceProvisionK8sRequestTag {
    /**
     * The name for the tag.
     */
    key: string;
    /**
     * The value for the tag.
     */
    value: string;
}

export interface OpdbOperationalDatabaseAttachedStorageForWorkers {
    /**
     * The number of Volumes. Default is 4. Valid Range: Minimum value of 1, maximum value 8.
     */
    volumeCount: number;
    /**
     * The target size of the volume, in GiB. Default is 2048.
     */
    volumeSize: number;
    /**
     * Volume Type. HDD - Hard disk drives (HDD) volume type. Default is HDD. SSD - Solid disk drives (SSD) volume type. LOCAL_SSD - Local SSD volume type.
     */
    volumeType: string;
}

export interface OpdbOperationalDatabaseAutoScalingParameters {
    /**
     * Period of metrics(in seconds) needs to be considered.
     */
    evaluationPeriod?: number;
    /**
     * The maximum number of compute nodes, as per these metrics, that can be scaled up to. It is only available in the BETA api.
     */
    maxComputeNodesForDatabase?: number;
    /**
     * The maximum percentage threshold for the CPU utilization of the worker nodes. The CPU utilization is obtained from the Cloudera Manager metric ‘cpu_percent’ across worker nodes. Set 100 or more to disable the CPU metrics. It is only available in the BETA api.
     */
    maxCpuUtilization?: number;
    /**
     * The maximum percentage of HDFS utilization for the database before we trigger the scaling. It is only available in the BETA api.
     */
    maxHdfsUsagePercentage?: number;
    /**
     * The maximum number of regions per region server. It is only available in the BETA api.
     */
    maxRegionsPerRegionServer?: number;
    /**
     * Maximum number of worker nodes as per this metrics can be scaled up to.
     */
    maxWorkersForDatabase?: number;
    /**
     * Maximum number of worker nodes as per this metrics can be scaled up to in one batch.
     */
    maxWorkersPerBatch?: number;
    /**
     * The minimum number of compute nodes, as per these metrics, that can be scaled down to. It is only available in the BETA api.
     */
    minComputeNodesForDatabase?: number;
    /**
     * Minimum number of worker nodes as per this metrics can be scaled down to.
     */
    minWorkersForDatabase?: number;
    /**
     * The amount of block cache, in Gigabytes, which the database should have.
     */
    minimumBlockCacheGb?: number;
    /**
     * The target value of the metric a user expect to maintain for the cluster
     */
    targetedValueForMetric?: number;
}

export interface OpdbOperationalDatabaseCustomUserTag {
    key: string;
    value: string;
}

export interface OpdbOperationalDatabaseImage {
    /**
     * Catalog name for the image.
     */
    catalog: string;
    /**
     * Image ID for the database.
     */
    id: string;
}

export interface OpdbOperationalDatabasePollingOptions {
    async: boolean;
    /**
     * Threshold value that specifies how many times should a single call failure happen before giving up the polling.
     */
    callFailureThreshold: number;
    /**
     * Timeout value in minutes that specifies for how long should the polling go for resource creation/deletion.
     */
    pollingTimeout: number;
}

export interface OpdbOperationalDatabaseRecipe {
    /**
     * The name of the designated instance group.
     */
    instanceGroup: string;
    /**
     * The set of recipe names that are going to be applied on the given instance group.
     */
    names: string[];
}

export interface OpdbOperationalDatabaseVolumeEncryption {
    /**
     * Encryption key to encrypt volume.
     */
    encryptionKey: string;
    /**
     * The name of the designated instance group.
     */
    instanceGroup: string;
}

