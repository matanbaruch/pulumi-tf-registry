// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "./types/input";
import * as outputs from "./types/output";
import * as utilities from "./utilities";

export function getKafkaClusterV2Instance(args: GetKafkaClusterV2InstanceArgs, opts?: pulumi.InvokeOptions): Promise<GetKafkaClusterV2InstanceResult> {

    opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts || {});
    return pulumi.runtime.invoke("instaclustr:index/getKafkaClusterV2Instance:getKafkaClusterV2Instance", {
        "allowDeleteTopics": args.allowDeleteTopics,
        "autoCreateTopics": args.autoCreateTopics,
        "bundledUseOnly": args.bundledUseOnly,
        "clientBrokerAuthWithMtls": args.clientBrokerAuthWithMtls,
        "clientToClusterEncryption": args.clientToClusterEncryption,
        "collocatedZookeepers": args.collocatedZookeepers,
        "currentClusterOperationStatus": args.currentClusterOperationStatus,
        "dataCentres": args.dataCentres,
        "dedicatedKraftControllers": args.dedicatedKraftControllers,
        "dedicatedZookeepers": args.dedicatedZookeepers,
        "defaultNumberOfPartitions": args.defaultNumberOfPartitions,
        "defaultReplicationFactor": args.defaultReplicationFactor,
        "defaultUserPassword": args.defaultUserPassword,
        "description": args.description,
        "id": args.id,
        "kafkaVersion": args.kafkaVersion,
        "karapaceRestProxies": args.karapaceRestProxies,
        "karapaceSchemaRegistries": args.karapaceSchemaRegistries,
        "krafts": args.krafts,
        "name": args.name,
        "pciComplianceMode": args.pciComplianceMode,
        "privateNetworkCluster": args.privateNetworkCluster,
        "resizeSettings": args.resizeSettings,
        "restProxies": args.restProxies,
        "schemaRegistries": args.schemaRegistries,
        "slaTier": args.slaTier,
        "status": args.status,
        "tieredStorages": args.tieredStorages,
        "twoFactorDeletes": args.twoFactorDeletes,
    }, opts, utilities.getPackage());
}

/**
 * A collection of arguments for invoking getKafkaClusterV2Instance.
 */
export interface GetKafkaClusterV2InstanceArgs {
    allowDeleteTopics?: boolean;
    autoCreateTopics?: boolean;
    bundledUseOnly?: boolean;
    clientBrokerAuthWithMtls?: boolean;
    clientToClusterEncryption?: boolean;
    collocatedZookeepers?: inputs.GetKafkaClusterV2InstanceCollocatedZookeeper[];
    currentClusterOperationStatus?: string;
    dataCentres?: inputs.GetKafkaClusterV2InstanceDataCentre[];
    dedicatedKraftControllers?: inputs.GetKafkaClusterV2InstanceDedicatedKraftController[];
    dedicatedZookeepers?: inputs.GetKafkaClusterV2InstanceDedicatedZookeeper[];
    defaultNumberOfPartitions?: number;
    defaultReplicationFactor?: number;
    defaultUserPassword?: string;
    description?: string;
    id: string;
    kafkaVersion?: string;
    karapaceRestProxies?: inputs.GetKafkaClusterV2InstanceKarapaceRestProxy[];
    karapaceSchemaRegistries?: inputs.GetKafkaClusterV2InstanceKarapaceSchemaRegistry[];
    krafts?: inputs.GetKafkaClusterV2InstanceKraft[];
    name?: string;
    pciComplianceMode?: boolean;
    privateNetworkCluster?: boolean;
    resizeSettings?: inputs.GetKafkaClusterV2InstanceResizeSetting[];
    restProxies?: inputs.GetKafkaClusterV2InstanceRestProxy[];
    schemaRegistries?: inputs.GetKafkaClusterV2InstanceSchemaRegistry[];
    slaTier?: string;
    status?: string;
    tieredStorages?: inputs.GetKafkaClusterV2InstanceTieredStorage[];
    twoFactorDeletes?: inputs.GetKafkaClusterV2InstanceTwoFactorDelete[];
}

/**
 * A collection of values returned by getKafkaClusterV2Instance.
 */
export interface GetKafkaClusterV2InstanceResult {
    readonly allowDeleteTopics: boolean;
    readonly autoCreateTopics: boolean;
    readonly bundledUseOnly: boolean;
    readonly clientBrokerAuthWithMtls: boolean;
    readonly clientToClusterEncryption: boolean;
    readonly collocatedZookeepers?: outputs.GetKafkaClusterV2InstanceCollocatedZookeeper[];
    readonly currentClusterOperationStatus: string;
    readonly dataCentres?: outputs.GetKafkaClusterV2InstanceDataCentre[];
    readonly dedicatedKraftControllers?: outputs.GetKafkaClusterV2InstanceDedicatedKraftController[];
    readonly dedicatedZookeepers?: outputs.GetKafkaClusterV2InstanceDedicatedZookeeper[];
    readonly defaultNumberOfPartitions: number;
    readonly defaultReplicationFactor: number;
    readonly defaultUserPassword: string;
    readonly description: string;
    readonly id: string;
    readonly kafkaVersion: string;
    readonly karapaceRestProxies?: outputs.GetKafkaClusterV2InstanceKarapaceRestProxy[];
    readonly karapaceSchemaRegistries?: outputs.GetKafkaClusterV2InstanceKarapaceSchemaRegistry[];
    readonly krafts?: outputs.GetKafkaClusterV2InstanceKraft[];
    readonly name: string;
    readonly pciComplianceMode: boolean;
    readonly privateNetworkCluster: boolean;
    readonly resizeSettings?: outputs.GetKafkaClusterV2InstanceResizeSetting[];
    readonly restProxies?: outputs.GetKafkaClusterV2InstanceRestProxy[];
    readonly schemaRegistries?: outputs.GetKafkaClusterV2InstanceSchemaRegistry[];
    readonly slaTier: string;
    readonly status: string;
    readonly tieredStorages?: outputs.GetKafkaClusterV2InstanceTieredStorage[];
    readonly twoFactorDeletes?: outputs.GetKafkaClusterV2InstanceTwoFactorDelete[];
}
export function getKafkaClusterV2InstanceOutput(args: GetKafkaClusterV2InstanceOutputArgs, opts?: pulumi.InvokeOptions): pulumi.Output<GetKafkaClusterV2InstanceResult> {
    return pulumi.output(args).apply((a: any) => getKafkaClusterV2Instance(a, opts))
}

/**
 * A collection of arguments for invoking getKafkaClusterV2Instance.
 */
export interface GetKafkaClusterV2InstanceOutputArgs {
    allowDeleteTopics?: pulumi.Input<boolean>;
    autoCreateTopics?: pulumi.Input<boolean>;
    bundledUseOnly?: pulumi.Input<boolean>;
    clientBrokerAuthWithMtls?: pulumi.Input<boolean>;
    clientToClusterEncryption?: pulumi.Input<boolean>;
    collocatedZookeepers?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceCollocatedZookeeperArgs>[]>;
    currentClusterOperationStatus?: pulumi.Input<string>;
    dataCentres?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceDataCentreArgs>[]>;
    dedicatedKraftControllers?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceDedicatedKraftControllerArgs>[]>;
    dedicatedZookeepers?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceDedicatedZookeeperArgs>[]>;
    defaultNumberOfPartitions?: pulumi.Input<number>;
    defaultReplicationFactor?: pulumi.Input<number>;
    defaultUserPassword?: pulumi.Input<string>;
    description?: pulumi.Input<string>;
    id: pulumi.Input<string>;
    kafkaVersion?: pulumi.Input<string>;
    karapaceRestProxies?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceKarapaceRestProxyArgs>[]>;
    karapaceSchemaRegistries?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceKarapaceSchemaRegistryArgs>[]>;
    krafts?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceKraftArgs>[]>;
    name?: pulumi.Input<string>;
    pciComplianceMode?: pulumi.Input<boolean>;
    privateNetworkCluster?: pulumi.Input<boolean>;
    resizeSettings?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceResizeSettingArgs>[]>;
    restProxies?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceRestProxyArgs>[]>;
    schemaRegistries?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceSchemaRegistryArgs>[]>;
    slaTier?: pulumi.Input<string>;
    status?: pulumi.Input<string>;
    tieredStorages?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceTieredStorageArgs>[]>;
    twoFactorDeletes?: pulumi.Input<pulumi.Input<inputs.GetKafkaClusterV2InstanceTwoFactorDeleteArgs>[]>;
}
